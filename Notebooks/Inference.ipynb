{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c9f8e4f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import TextVectorization\n",
    "\n",
    "\n",
    "\n",
    "model_path = \"../Results/model_5_acc_85_loss_41/\"\n",
    "\n",
    "loaded_model = tf.keras.models.load_model(model_path)\n",
    "                                        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1348734",
   "metadata": {},
   "source": [
    "* Split it into sentences (lines).\n",
    "* split into characters\n",
    "* find number of each line\n",
    "* find number of total lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dddd7b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e22b5e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"skimlit_example_abstracts.json\", \"r\") as f:\n",
    "    example_abstracts = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0936408",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract</th>\n",
       "      <th>source</th>\n",
       "      <th>details</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This RCT examined the efficacy of a manualized...</td>\n",
       "      <td>https://pubmed.ncbi.nlm.nih.gov/20232240/</td>\n",
       "      <td>RCT of a manualized social treatment for high-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Postpartum depression (PPD) is the most preval...</td>\n",
       "      <td>https://pubmed.ncbi.nlm.nih.gov/28012571/</td>\n",
       "      <td>Formatting removed (can be used to compare mod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mental illness, including depression, anxiety ...</td>\n",
       "      <td>https://pubmed.ncbi.nlm.nih.gov/28942748/</td>\n",
       "      <td>Effect of nutrition on mental health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hepatitis C virus (HCV) and alcoholic liver di...</td>\n",
       "      <td>https://pubmed.ncbi.nlm.nih.gov/22244707/</td>\n",
       "      <td>Baclofen promotes alcohol abstinence in alcoho...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            abstract  \\\n",
       "0  This RCT examined the efficacy of a manualized...   \n",
       "1  Postpartum depression (PPD) is the most preval...   \n",
       "2  Mental illness, including depression, anxiety ...   \n",
       "3  Hepatitis C virus (HCV) and alcoholic liver di...   \n",
       "\n",
       "                                      source  \\\n",
       "0  https://pubmed.ncbi.nlm.nih.gov/20232240/   \n",
       "1  https://pubmed.ncbi.nlm.nih.gov/28012571/   \n",
       "2  https://pubmed.ncbi.nlm.nih.gov/28942748/   \n",
       "3  https://pubmed.ncbi.nlm.nih.gov/22244707/   \n",
       "\n",
       "                                             details  \n",
       "0  RCT of a manualized social treatment for high-...  \n",
       "1  Formatting removed (can be used to compare mod...  \n",
       "2               Effect of nutrition on mental health  \n",
       "3  Baclofen promotes alcohol abstinence in alcoho...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abstracts = pd.DataFrame(example_abstracts)\n",
    "abstracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15de12f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\EL AIDI\n",
      "[nltk_data]     MOHAMED\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['This RCT examined the efficacy of a manualized social intervention for children with HFASDs.',\n",
       " 'Participants were randomly assigned to treatment or wait-list conditions.',\n",
       " 'Treatment included instruction and therapeutic activities targeting social skills, face-emotion recognition, interest expansion, and interpretation of non-literal language.',\n",
       " 'A response-cost program was applied to reduce problem behaviors and foster skills acquisition.',\n",
       " 'Significant treatment effects were found for five of seven primary outcome measures (parent ratings and direct child measures).',\n",
       " 'Secondary measures based on staff ratings (treatment group only) corroborated gains reported by parents.',\n",
       " 'High levels of parent, child and staff satisfaction were reported, along with high levels of treatment fidelity.',\n",
       " 'Standardized effect size estimates were primarily in the medium and large ranges and favored the treatment group.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('punkt')  # Download the Punkt tokenizer models\n",
    "\n",
    "# Example text\n",
    "example_text = example_abstracts[0][\"abstract\"]\n",
    "\n",
    "# Use NLTK for sentence splitting\n",
    "abstract_lines = nltk.sent_tokenize(example_text)\n",
    "\n",
    "abstract_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9ae6c01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'This RCT examined the efficacy of a manualized social intervention for children with HFASDs.',\n",
       "  'line_number': 0,\n",
       "  'total_lines': 7},\n",
       " {'text': 'Participants were randomly assigned to treatment or wait-list conditions.',\n",
       "  'line_number': 1,\n",
       "  'total_lines': 7},\n",
       " {'text': 'Treatment included instruction and therapeutic activities targeting social skills, face-emotion recognition, interest expansion, and interpretation of non-literal language.',\n",
       "  'line_number': 2,\n",
       "  'total_lines': 7},\n",
       " {'text': 'A response-cost program was applied to reduce problem behaviors and foster skills acquisition.',\n",
       "  'line_number': 3,\n",
       "  'total_lines': 7},\n",
       " {'text': 'Significant treatment effects were found for five of seven primary outcome measures (parent ratings and direct child measures).',\n",
       "  'line_number': 4,\n",
       "  'total_lines': 7},\n",
       " {'text': 'Secondary measures based on staff ratings (treatment group only) corroborated gains reported by parents.',\n",
       "  'line_number': 5,\n",
       "  'total_lines': 7},\n",
       " {'text': 'High levels of parent, child and staff satisfaction were reported, along with high levels of treatment fidelity.',\n",
       "  'line_number': 6,\n",
       "  'total_lines': 7},\n",
       " {'text': 'Standardized effect size estimates were primarily in the medium and large ranges and favored the treatment group.',\n",
       "  'line_number': 7,\n",
       "  'total_lines': 7}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get total number of lines\n",
    "total_lines_in_sample = len(abstract_lines)\n",
    "\n",
    "# Go through each line in abstract and create a list of dictionaries containing features for each line\n",
    "sample_lines = []\n",
    "for i, line in enumerate(abstract_lines):\n",
    "    sample_dict = {}\n",
    "    sample_dict[\"text\"] = str(line)\n",
    "    sample_dict[\"line_number\"] = i\n",
    "    sample_dict[\"total_lines\"] = total_lines_in_sample - 1\n",
    "    sample_lines.append(sample_dict)\n",
    "\n",
    "sample_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9842b0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(8, 15), dtype=float32, numpy=\n",
       "array([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all line_number values from sample abstract\n",
    "test_abstract_line_numbers = [line[\"line_number\"] for line in sample_lines]\n",
    "\n",
    "# One-hot encode to same depth as training data, so model accepts right input shape\n",
    "test_abstract_line_numbers_one_hot = tf.one_hot(test_abstract_line_numbers, depth=15) \n",
    "test_abstract_line_numbers_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ab5f567",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(8, 20), dtype=float32, numpy=\n",
       "array([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all total_lines values from sample abstract\n",
    "test_abstract_total_lines = [line[\"total_lines\"] for line in sample_lines]\n",
    "# One-hot encode to same depth as training data, so model accepts right input shape\n",
    "test_abstract_total_lines_one_hot = tf.one_hot(test_abstract_total_lines, depth=20)\n",
    "test_abstract_total_lines_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e6eb8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_chars(text):\n",
    "    return ' '.join(list(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "916d34dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split abstract lines into characters\n",
    "abstract_chars = [split_chars(sentence) for sentence in abstract_lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3696819c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(8, 15), dtype=float32, numpy=\n",
       "array([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_abstract_line_numbers_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9817847a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(8, 20), dtype=float32, numpy=\n",
       "array([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_abstract_total_lines_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "39decd27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(8,), dtype=string, numpy=\n",
       "array([b'This RCT examined the efficacy of a manualized social intervention for children with HFASDs.',\n",
       "       b'Participants were randomly assigned to treatment or wait-list conditions.',\n",
       "       b'Treatment included instruction and therapeutic activities targeting social skills, face-emotion recognition, interest expansion, and interpretation of non-literal language.',\n",
       "       b'A response-cost program was applied to reduce problem behaviors and foster skills acquisition.',\n",
       "       b'Significant treatment effects were found for five of seven primary outcome measures (parent ratings and direct child measures).',\n",
       "       b'Secondary measures based on staff ratings (treatment group only) corroborated gains reported by parents.',\n",
       "       b'High levels of parent, child and staff satisfaction were reported, along with high levels of treatment fidelity.',\n",
       "       b'Standardized effect size estimates were primarily in the medium and large ranges and favored the treatment group.'],\n",
       "      dtype=object)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant(abstract_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ba19705",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(8,), dtype=string, numpy=\n",
       "array([b'T h i s   R C T   e x a m i n e d   t h e   e f f i c a c y   o f   a   m a n u a l i z e d   s o c i a l   i n t e r v e n t i o n   f o r   c h i l d r e n   w i t h   H F A S D s .',\n",
       "       b'P a r t i c i p a n t s   w e r e   r a n d o m l y   a s s i g n e d   t o   t r e a t m e n t   o r   w a i t - l i s t   c o n d i t i o n s .',\n",
       "       b'T r e a t m e n t   i n c l u d e d   i n s t r u c t i o n   a n d   t h e r a p e u t i c   a c t i v i t i e s   t a r g e t i n g   s o c i a l   s k i l l s ,   f a c e - e m o t i o n   r e c o g n i t i o n ,   i n t e r e s t   e x p a n s i o n ,   a n d   i n t e r p r e t a t i o n   o f   n o n - l i t e r a l   l a n g u a g e .',\n",
       "       b'A   r e s p o n s e - c o s t   p r o g r a m   w a s   a p p l i e d   t o   r e d u c e   p r o b l e m   b e h a v i o r s   a n d   f o s t e r   s k i l l s   a c q u i s i t i o n .',\n",
       "       b'S i g n i f i c a n t   t r e a t m e n t   e f f e c t s   w e r e   f o u n d   f o r   f i v e   o f   s e v e n   p r i m a r y   o u t c o m e   m e a s u r e s   ( p a r e n t   r a t i n g s   a n d   d i r e c t   c h i l d   m e a s u r e s ) .',\n",
       "       b'S e c o n d a r y   m e a s u r e s   b a s e d   o n   s t a f f   r a t i n g s   ( t r e a t m e n t   g r o u p   o n l y )   c o r r o b o r a t e d   g a i n s   r e p o r t e d   b y   p a r e n t s .',\n",
       "       b'H i g h   l e v e l s   o f   p a r e n t ,   c h i l d   a n d   s t a f f   s a t i s f a c t i o n   w e r e   r e p o r t e d ,   a l o n g   w i t h   h i g h   l e v e l s   o f   t r e a t m e n t   f i d e l i t y .',\n",
       "       b'S t a n d a r d i z e d   e f f e c t   s i z e   e s t i m a t e s   w e r e   p r i m a r i l y   i n   t h e   m e d i u m   a n d   l a r g e   r a n g e s   a n d   f a v o r e d   t h e   t r e a t m e n t   g r o u p .'],\n",
       "      dtype=object)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant(abstract_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1613df6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bede8df0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2.17811748e-01, 2.57731928e-03, 2.65421288e-04, 7.79298306e-01,\n",
       "        4.71834610e-05],\n",
       "       [1.89512828e-03, 1.40211205e-05, 9.86449540e-01, 2.19070236e-03,\n",
       "        9.45061632e-03],\n",
       "       [1.17194615e-02, 1.83234311e-04, 9.32980299e-01, 1.53515432e-02,\n",
       "        3.97654399e-02],\n",
       "       [4.38626632e-02, 5.46142645e-03, 7.01393485e-01, 3.41751352e-02,\n",
       "        2.15107247e-01],\n",
       "       [9.11207928e-04, 6.10383134e-03, 1.34519294e-01, 5.85712376e-04,\n",
       "        8.57879996e-01],\n",
       "       [7.10648950e-04, 3.31444712e-03, 8.44479799e-01, 3.44797008e-04,\n",
       "        1.51150331e-01],\n",
       "       [1.32539251e-04, 5.74295558e-02, 8.33371188e-03, 3.50271876e-05,\n",
       "        9.34069157e-01],\n",
       "       [1.99921469e-05, 4.95938547e-02, 3.00278850e-02, 9.75907187e-06,\n",
       "        9.20348525e-01]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions on sample abstract features\n",
    "test_abstract_pred_probs = loaded_model.predict(x=(test_abstract_line_numbers_one_hot,\n",
    "                                                   test_abstract_total_lines_one_hot,\n",
    "                                                   tf.constant(abstract_lines),\n",
    "                                                   tf.constant(abstract_chars)))\n",
    "test_abstract_pred_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "42c422b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OBJECTIVE: This RCT examined the efficacy of a manualized social intervention for children with HFASDs.\n",
      "METHODS: Participants were randomly assigned to treatment or wait-list conditions.\n",
      "METHODS: Treatment included instruction and therapeutic activities targeting social skills, face-emotion recognition, interest expansion, and interpretation of non-literal language.\n",
      "METHODS: A response-cost program was applied to reduce problem behaviors and foster skills acquisition.\n",
      "RESULTS: Significant treatment effects were found for five of seven primary outcome measures (parent ratings and direct child measures).\n",
      "METHODS: Secondary measures based on staff ratings (treatment group only) corroborated gains reported by parents.\n",
      "RESULTS: High levels of parent, child and staff satisfaction were reported, along with high levels of treatment fidelity.\n",
      "RESULTS: Standardized effect size estimates were primarily in the medium and large ranges and favored the treatment group.\n"
     ]
    }
   ],
   "source": [
    "# Turn prediction probabilities into prediction classes\n",
    "test_abstract_preds = tf.argmax(test_abstract_pred_probs, axis=1)\n",
    "test_abstract_preds\n",
    "classes = ['BACKGROUND', 'CONCLUSIONS', 'METHODS', 'OBJECTIVE', 'RESULTS']\n",
    "# Turn prediction class integers into string class names\n",
    "test_abstract_pred_classes = [classes[i] for i in test_abstract_preds]\n",
    "test_abstract_pred_classes\n",
    "# Visualize abstract lines and predicted sequence labels\n",
    "for i, line in enumerate(abstract_lines):\n",
    "    print(f\"{test_abstract_pred_classes[i]}: {line}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ea7e3b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import tensorflow as tf\n",
    "\n",
    "def nltk_function(abstract):\n",
    "    # Tokenize sentences using NLTK\n",
    "    abstract_lines = sent_tokenize(abstract)\n",
    "    return abstract_lines\n",
    "\n",
    "# ---------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "def split_chars(text):\n",
    "    return ' '.join(list(text))\n",
    "\n",
    "# ---------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "def make_predictions(text):\n",
    "    classes = ['BACKGROUND', 'CONCLUSIONS', 'METHODS', 'OBJECTIVE', 'RESULTS']\n",
    "    abstract_lines = list()\n",
    "\n",
    "    abstract_lines = nltk_function(text)\n",
    "\n",
    "    # Get total number of lines\n",
    "    total_lines_in_sample = len(abstract_lines)\n",
    "\n",
    "    # Go through each line in abstract and create a list of dictionaries containing features for each line\n",
    "    sample_lines = []\n",
    "    for i, line in enumerate(abstract_lines):\n",
    "        sample_dict = {}\n",
    "        sample_dict[\"text\"] = str(line)\n",
    "        sample_dict[\"line_number\"] = i\n",
    "        sample_dict[\"total_lines\"] = total_lines_in_sample - 1\n",
    "        sample_lines.append(sample_dict)\n",
    "\n",
    "    # Get all line_number values from the sample abstract\n",
    "    test_abstract_line_numbers = [line[\"line_number\"] for line in sample_lines]\n",
    "\n",
    "    # One-hot encode to the same depth as training data so that the model accepts the right input shape\n",
    "    test_abstract_line_numbers_one_hot = tf.one_hot(test_abstract_line_numbers, depth=15)\n",
    "\n",
    "    # Get all total_lines values from the sample abstract\n",
    "    test_abstract_total_lines = [line[\"total_lines\"] for line in sample_lines]\n",
    "\n",
    "    # One-hot encode to the same depth as training data so that the model accepts the right input shape\n",
    "    test_abstract_total_lines_one_hot = tf.one_hot(test_abstract_total_lines, depth=20)\n",
    "\n",
    "    # Split abstract lines into characters\n",
    "    abstract_chars = [split_chars(sentence) for sentence in abstract_lines]\n",
    "\n",
    "    # Make predictions on sample abstract features\n",
    "    test_abstract_pred_probs = loaded_model.predict(x=(test_abstract_line_numbers_one_hot,\n",
    "                                                       test_abstract_total_lines_one_hot,\n",
    "                                                       tf.constant(abstract_lines),\n",
    "                                                       tf.constant(abstract_chars)))\n",
    "\n",
    "    test_abstract_preds = tf.argmax(test_abstract_pred_probs, axis=1)\n",
    "\n",
    "    test_abstract_pred_classes = [classes[i] for i in test_abstract_preds]\n",
    "    \n",
    "    \n",
    "    \n",
    "    BACKGROUND = \"\"\n",
    "    CONCLUSIONS = \"\"\n",
    "    METHODS = \"\"\n",
    "    OBJECTIVE = \"\"\n",
    "    RESULTS = \"\"\n",
    "\n",
    "    for i, line in enumerate(abstract_lines):\n",
    "        print(f\"{test_abstract_pred_classes[i]}: {line}\")\n",
    "\n",
    "        current_class = test_abstract_pred_classes[i]\n",
    "\n",
    "        if current_class == \"BACKGROUND\":\n",
    "            BACKGROUND += line\n",
    "        elif current_class == \"CONCLUSIONS\":\n",
    "            CONCLUSIONS += line\n",
    "        elif current_class == \"METHODS\":\n",
    "            METHODS += line\n",
    "        elif current_class == \"OBJECTIVE\":\n",
    "            OBJECTIVE += line\n",
    "        elif current_class == \"RESULTS\":\n",
    "            RESULTS += line\n",
    "        \n",
    "\n",
    "    print(BACKGROUND)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a911e3b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 37ms/step\n",
      "BACKGROUND: \n",
      "The Darknet is an encrypted corner of the internet,\n",
      "intended for users who wish to remain anonymous and mask\n",
      "their identity.\n",
      "BACKGROUND: Because of its anonymous qualities, the Darknet\n",
      "has become a go-to platform for illicit activities such as drug\n",
      "trafficking, terrorism, and dark marketplaces.\n",
      "BACKGROUND: Therefore, it is\n",
      "important to recognize Darknet traffic in order to monitor and\n",
      "detect malicious online activities.\n",
      "OBJECTIVE: This paper investigates the\n",
      "potential effectiveness of machine learning algorithms in identifying attacks using the CICdarknet2020 dataset.\n",
      "METHODS: The dataset\n",
      "includes two distinct classification targets: traffic label and\n",
      "application labels.\n",
      "CONCLUSIONS: The objective of our research is to identify\n",
      "optimal classifiers for traffic and application classification by\n",
      "employing ensemble learning methods, aiming to achieve the\n",
      "highest possible results.\n",
      "CONCLUSIONS: Through our experimentation, we have\n",
      "found that the best-performing models surpassing all other state of-the-art machine learning models are LightGBM, achieving a\n",
      "93.41% f1-score in the Application classification, and Random\n",
      "Forest, achieving a 99.8% f1-score in the traffic classification.\n",
      "\n",
      "The Darknet is an encrypted corner of the internet,\n",
      "intended for users who wish to remain anonymous and mask\n",
      "their identity.Because of its anonymous qualities, the Darknet\n",
      "has become a go-to platform for illicit activities such as drug\n",
      "trafficking, terrorism, and dark marketplaces.Therefore, it is\n",
      "important to recognize Darknet traffic in order to monitor and\n",
      "detect malicious online activities.\n"
     ]
    }
   ],
   "source": [
    "# Example abstract text\n",
    "example_abstract = \"\"\"\n",
    "The Darknet is an encrypted corner of the internet,\n",
    "intended for users who wish to remain anonymous and mask\n",
    "their identity. Because of its anonymous qualities, the Darknet\n",
    "has become a go-to platform for illicit activities such as drug\n",
    "trafficking, terrorism, and dark marketplaces. Therefore, it is\n",
    "important to recognize Darknet traffic in order to monitor and\n",
    "detect malicious online activities. This paper investigates the\n",
    "potential effectiveness of machine learning algorithms in identifying attacks using the CICdarknet2020 dataset. The dataset\n",
    "includes two distinct classification targets: traffic label and\n",
    "application labels. The objective of our research is to identify\n",
    "optimal classifiers for traffic and application classification by\n",
    "employing ensemble learning methods, aiming to achieve the\n",
    "highest possible results. Through our experimentation, we have\n",
    "found that the best-performing models surpassing all other state of-the-art machine learning models are LightGBM, achieving a\n",
    "93.41% f1-score in the Application classification, and Random\n",
    "Forest, achieving a 99.8% f1-score in the traffic classification.\"\"\"\n",
    "\n",
    "text_predict = make_predictions(example_abstract)\n",
    "text_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6181559c",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 25\u001b[0m\n\u001b[0;32m     21\u001b[0m         regrouped_text[section] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(content)\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m regrouped_text\n\u001b[1;32m---> 25\u001b[0m \u001b[43mregroup_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext_predict\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[21], line 11\u001b[0m, in \u001b[0;36mregroup_text\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m      2\u001b[0m sections \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBACKGROUND\u001b[39m\u001b[38;5;124m'\u001b[39m: [],\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMETHODS\u001b[39m\u001b[38;5;124m'\u001b[39m: [],\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRESULTS\u001b[39m\u001b[38;5;124m'\u001b[39m: [],\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCONCLUSIONS\u001b[39m\u001b[38;5;124m'\u001b[39m: []\n\u001b[0;32m      7\u001b[0m }\n\u001b[0;32m      9\u001b[0m current_section \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m     12\u001b[0m     line \u001b[38;5;241m=\u001b[39m line\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m sections:\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "def regroup_text(text):\n",
    "    sections = {\n",
    "        'BACKGROUND': [],\n",
    "        'METHODS': [],\n",
    "        'RESULTS': [],\n",
    "        'CONCLUSIONS': []\n",
    "    }\n",
    "\n",
    "    current_section = None\n",
    "\n",
    "    for line in text.split('\\n'):\n",
    "        line = line.strip()\n",
    "        if line in sections:\n",
    "            current_section = line\n",
    "        elif current_section:\n",
    "            sections[current_section].append(line)\n",
    "\n",
    "    regrouped_text = {}\n",
    "\n",
    "    for section, content in sections.items():\n",
    "        regrouped_text[section] = ' '.join(content)\n",
    "\n",
    "    return regrouped_text\n",
    "\n",
    "regroup_text(text_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975e9a05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
